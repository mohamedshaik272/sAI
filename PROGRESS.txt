sAI Project Progress - Feb 14, 2025
=====================================

## What's Been Done

### 1. VRM Avatar Model
- Downloaded fem_vroid.vrm from github.com/madjin/vrm-samples as placeholder
- Saved to: frontend/public/models/avatar.vrm
- NOTE: This is a raw/undressed model. Need to replace with a proper character.
  Best source: VRoid Hub (hub.vroid.com) - free account, tons of dressed characters.

### 2. Fixed Circular Import Bug
- PROBLEM: backend/elevenlabs.py and backend/whisper.py shadowed the installed packages
- FIX: Renamed elevenlabs.py -> tts.py, whisper.py -> stt.py
- Deleted the old elevenlabs.py and whisper.py files
- Updated app.py imports accordingly

### 3. Natural Idle Animations (avatar.js)
- PROBLEM: VRM model loaded in T-pose (arms out, no movement)
- FIX: Added setRestingPose() that runs on model load:
  - Arms rotated ~70 degrees down to sides
  - Slight elbow bend, relaxed hands
- Added natural idle animations:
  - Smooth blinking (gradual open/close, randomized 2-6s intervals)
  - Breathing cycle (chest + spine rise/fall)
  - Head micro-movements (layered sine waves for organic feel)
  - Subtle arm sway on top of resting pose
  - Hip weight shifting
- Tunable via REST_POSE object at top of avatar.js

### 4. Desktop Mic Architecture
- PROBLEM: Phone couldn't access mic (denied), and we want desktop mic anyway
- FIX: Changed architecture so phone is just display + speaker:
  - Frontend sends "start_listening" / "stop_listening" commands via WebSocket
  - Backend captures audio from desktop mic using sounddevice (sd.InputStream)
  - Backend processes: Whisper STT -> Gemini LLM -> ElevenLabs TTS
  - Sends audio back to phone for playback + lip-sync

### 5. Mobile Audio Playback Fix
- PROBLEM: new Audio().play() blocked on mobile browsers without user gesture
- FIX: Switched to AudioContext.decodeAudioData() + BufferSource
  - AudioContext unlocked on first mic button tap (user gesture)
  - Shared single AudioContext instance across app

### 6. Added Print Statements to Backend
- Full debug logging in app.py: [WS], [MIC], [STT], [TTS], [LLM], [ERROR] prefixes
- Backend must be run with PYTHONUNBUFFERED=1 for logs to show on Windows

### 7. WebSocket Stability Fixes
- PROBLEM: Phone connection dropping, reconnect loops stacking, lip-sync leak
- FIXES:
  - Added reconnect guard (prevents multiple reconnect timers stacking)
  - Added ping/pong keepalive (frontend pings every 15s, backend responds)
  - Fixed lip-sync animation loop (used nonexistent playbackState, replaced with boolean flag)
  - Frontend resets recording state and mic button on disconnect
  - Both sides handle malformed JSON gracefully

### 8. Fixed .env Loading Path
- PROBLEM: config.py used load_dotenv() which searches CWD, but uvicorn CWD was repo root, not backend/
- FIX: Changed to load_dotenv(Path(__file__).parent / ".env") for explicit path

### 9. Gemini LLM Integration
- PROBLEM: gemini.py was empty, conversation just echoed user input
- FIX: Teammate implemented gemini.py with system prompt + config (google-genai SDK)
  - Medical assistant persona with safety guardrails
  - Thinking config set to LOW for speed
  - Lifespan-managed Gemini client in app.state
  - /api/test POST endpoint for standalone testing
  - Wired into WebSocket conversation loop (replaces echo)
- Installed google-genai package (was google-generativeai before)

## Current State

### Working (Tested End-to-End)
- Full conversation loop: Mic -> Whisper STT -> Gemini LLM -> ElevenLabs TTS -> Audio playback + lip-sync
- Backend starts: cd sAI/backend && PYTHONUNBUFFERED=1 ./venv/Scripts/python -m uvicorn app:app --host 0.0.0.0 --port 8000 --reload
- Frontend starts: cd sAI/frontend && npm run dev
- All dependencies installed (venv for Python, node_modules for frontend)
- Health endpoint: http://localhost:8000/health returns {"status":"ok"}
- Gemini test endpoint: POST http://localhost:8000/api/test with {"prompt": "..."}
- Phone can access frontend via network IP
- VRM avatar renders with natural idle animations
- WebSocket connects with ping/pong keepalive
- Gemini responds as medical assistant (tested: "Hello, what is your name?" -> real response)

### Known Issues
- Phone shows "connecting" if WebSocket can't reach backend on port 8000
- Need to test on phone over hotspot/shared network

### Not Implemented Yet
- Arduino servo_control is a TODO placeholder
- Body tracking (tracking.py with MediaPipe) exists but not integrated into main loop
- Need a proper VRM character model (clothed, styled)
- No conversation memory/history (each message is standalone)

## File Structure (key files)
backend/
  app.py          - Main FastAPI server (WebSocket + Gemini + desktop mic + debug logging)
  stt.py          - Whisper STT (was whisper.py, renamed to avoid shadowing)
  tts.py          - ElevenLabs TTS (was elevenlabs.py, renamed to avoid shadowing)
  gemini.py       - Gemini LLM config, system prompt, request model
  config.py       - API keys from .env (explicit path loading)
  tracking.py     - MediaPipe body tracking (unchanged, not yet integrated)
  .env            - Has ELEVENLABS_API_KEY, ELEVENLABS_VOICE_ID, GEMINI_API_KEY

frontend/
  src/main.js     - WebSocket comm, ping/pong keepalive, AudioContext playback, lip-sync
  src/avatar.js   - VRM rendering, resting pose, idle animations, lip-sync expressions
  index.html      - Unchanged
  public/models/avatar.vrm - Downloaded placeholder model

## Next Steps (Priority Order)
1. Get a proper VRM model from VRoid Hub
2. Arduino servo control for rotating hologram base
3. Integrate body tracking for servo angle mapping
4. Add conversation memory/history
5. Test on phone over network

## How to Run
1. Backend: cd sAI/backend && PYTHONUNBUFFERED=1 ./venv/Scripts/python -m uvicorn app:app --host 0.0.0.0 --port 8000 --reload
2. Frontend: cd sAI/frontend && npm run dev
3. Open http://localhost:3000 on desktop or http://<your-network-ip>:3000 on phone

## API Keys (.env)
- ElevenLabs key and voice ID are set
- Gemini API key is set
- All keys in backend/.env
